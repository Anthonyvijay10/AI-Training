{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f4d35b-d8b1-47b7-a1d3-07e41b2d2129",
   "metadata": {},
   "source": [
    "In this description, we'll explore the operation of four neurons followed by the Rectified Linear Unit (ReLU) activation function.\n",
    "1. ##### Input Layer : \n",
    "   - The input layer represents the input features to the neurons. It's typically represented as a row vector where each element corresponds to an      input feature.\n",
    "   - For four neurons, the input layer would typically consist of four elements:\n",
    "     $$ \\text{Input Layer} = \\begin{bmatrix} 1 & 2 & 3 & 4 \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c585b75b-8ebc-4484-85a3-98baa6386ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define input tensor (1 sample, 4 features)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0, 4.0]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248df1a-6c98-4b6d-903b-d09b8f38ecf0",
   "metadata": {},
   "source": [
    "2. **Weights**:\n",
    "   - Weights are the parameters of the neuron that are learned during the training process. Each weight corresponds to a connection between an input feature and the neuron.\n",
    "   - Weights are typically represented as a column vector:\n",
    "     $$\r\n",
    "\\text{Weights} = \\begin{bmatrix}\r\n",
    "-1 & 1 & 0 & 0 \\\\\r\n",
    "0 & -1 & 1 & 0 \\\\\r\n",
    "0 & 0 & -1 & 1 \\\\\r\n",
    "1 & 0 & 0 & -1 \\\\\r\n",
    "\\end{bmatrix}\r\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95868258-40bd-4ea0-b224-424a64c18c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  1.,  0.,  0.],\n",
       "        [ 0., -1.,  1.,  0.],\n",
       "        [ 0.,  0., -1.,  1.],\n",
       "        [ 1.,  0.,  0., -1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights\n",
    "weights = torch.tensor([[-1.0, 1.0, 0.0, 0.0],\n",
    "                        [0.0, -1.0, 1.0, 0.0],\n",
    "                        [0.0, 0.0, -1.0, 1.0],\n",
    "                        [1.0, 0.0, 0.0, -1.0]])\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab0b72-914b-44fb-b7dc-f92a78349d4f",
   "metadata": {},
   "source": [
    "3. **Bias**:\n",
    "   - The bias term is another parameter of the neuron. It's added to the weighted sum of inputs to shift the activation function.\n",
    "   - The bias is represented as a scalar value:\n",
    "     $$\n",
    "     \\text{b} = \\begin{bmatrix} -5 & 0 & 1 & 2 \\end{bmatrix}\n",
    "     $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54fe38bd-972d-42eb-bf74-0e12f294c478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bias\n",
    "bias = torch.tensor([-5.0, 0.0, 1.0, 2.0])\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea0ab6-9301-4c44-8e9e-e609823143e2",
   "metadata": {},
   "source": [
    "4. **Linear Transformation**:\n",
    "   - This represents the result of the linear transformation of the input by the neuron, including the weighted sum of inputs and the bias term.\n",
    "   - It's computed by multiplying the input layer by the weights and then adding the bias term:\n",
    "  \n",
    "     $$\n",
    "     \\text{Linear Output} = W . X^T + B\n",
    "     $$\n",
    "\n",
    "     $$\n",
    "     \\text{\\ \\ \\ \\ \\ \\ } = \\begin{bmatrix}\n",
    "        -1 & 1 & 0 & 0 \\\\\n",
    "        0 & -1 & 1 & 0 \\\\\n",
    "        0 & 0 & -1 & 1 \\\\\n",
    "        1 & 0 & 0 & -1 \\\\\n",
    "                            \\end{bmatrix}\n",
    "     \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{bmatrix} + \\begin{bmatrix} -5 \\\\ 0 \\\\ 1 \\\\ 2 \\end{bmatrix}\n",
    "    $$\n",
    "    $$\n",
    "    = \\begin{bmatrix} -2 \\\\ -1 \\\\ 0 \\\\ 1 \\end{bmatrix}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aff44b81-c192-43f6-8de1-26ebd33c303a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.],\n",
       "        [-1.],\n",
       "        [ 0.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output = torch.matmul(x, weights) + bias\n",
    "linear_output.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6840cb-5439-4797-a3bf-e6b0391b7e21",
   "metadata": {},
   "source": [
    "5. **ReLU Activation**:\n",
    "   - ReLU (Rectified Linear Unit) is an activation function commonly used in neural networks to introduce non-linearity.\n",
    "   - It applies an element-wise operation to the output of Step 1, replacing any negative values with zero:\n",
    "      $$ \\text{ReLU}([-2,-1,0,1]) = [0,0,0,1] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "058ee187-49f9-4d5c-be19-aa2aafa497ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU output: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# ReLU activation\n",
    "relu_output = nn.functional.relu(linear_output.T)\n",
    "\n",
    "# Output\n",
    "print(\"ReLU output:\", relu_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60fc16-7c5a-4299-8e8b-b53140540f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
