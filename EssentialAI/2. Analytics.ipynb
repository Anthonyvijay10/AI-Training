{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc8abc7-6b88-4363-885d-8d95a7b09e03",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <h1>Text-Vision-Voice Analytics</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f044d239-dbd4-45aa-a27a-16a6fb7b2005",
   "metadata": {},
   "source": [
    "Analytics refers to the application of artificial intelligence and machine learning techniques to analyze and **derive insights** from **data**. It combines the power of AI with data analytics to automate and enhance **data-driven decision-making** processes. AI analytics **leverages ML algorithms and ML models** to uncover **patterns, trends, and valuable information** from large and complex datasets that would be **challenging for humans to process manually**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba0095a-0465-4750-8f82-b0000d2a6611",
   "metadata": {},
   "source": [
    "### Text Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bfdf80-0c0c-4fd6-b4a3-e239f38338b1",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/13.jpg\" alt=\"https://www.sciencedirect.com/topics/mathematics/text-analytics\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0d6cf-f3ea-4fe0-a763-d9c47ec1d79f",
   "metadata": {},
   "source": [
    "#### Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e147256-80a9-4192-9c8a-09c37b336d38",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/15.png\" alt=\"https://www.analyticsvidhya.com/blog/2022/07/sentiment-analysis-using-python/\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02568311-3145-4451-8c7a-eab84e9c99a1",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/16.png\" alt=\"https://www.analyticsvidhya.com/blog/2022/07/sentiment-analysis-using-python/\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0f923-126c-44c4-ae58-5223d947d8ce",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5a3a8-5079-4a1b-a7af-379a8f3b6503",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/17.jpg\" alt=\"https://www.shaip.com/blog/named-entity-recognition-and-its-types/\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95180c91-8e13-4f5d-9bb5-9a42a289573b",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/18.jpg\" alt=\"https://www.yext.com/platform/features/named-entity-recognition\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2207e9-9adb-4658-8868-e1d814ee1ae1",
   "metadata": {},
   "source": [
    "#### Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fdbe25-acd1-47dd-98d4-5d13bf2fd4e5",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/17.png\" alt=\"https://www.semanticscholar.org/paper/Methods-for-open-information-extraction-and-sense-Corro/3afc8190029c83627e0f4dadca67d422261d2616/figure/2\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc9fa1-f66a-48e2-bf99-5d649a79ad13",
   "metadata": {},
   "source": [
    "#### Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c78bf-d6e4-4f4e-8c69-a193ef55bb92",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/19.png\" alt=\"\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7213620-e5b4-4400-a34f-ab16087efb58",
   "metadata": {},
   "source": [
    "#### Text Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8eee1-1510-44b7-9a99-87db9c36a586",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/18.png\" alt=\"\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629286eb-7db9-405e-abe1-f6d84f30011a",
   "metadata": {},
   "source": [
    "#### Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0a617-5298-4adc-b80e-8993893b2a39",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/19.jpg\" alt=\"https://paperswithcode.com/task/question-answering\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4867a-37ed-4d87-a5ef-be67605426a1",
   "metadata": {},
   "source": [
    "#### Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01a66e-7f7b-4447-8c9c-63fee268f766",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/20.png\" alt=\"https://turbolab.in/types-of-text-summarization-extractive-and-abstractive-summarization-basics/\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4797c897-1bfe-4c05-975a-7a2c6c2ee969",
   "metadata": {},
   "source": [
    "#### Co-Reference Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e134cf8-d460-42c7-87dd-0ab07cff55ce",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/21.png\" alt=\"https://towardsai.net/p/nlp/c-r\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5aaa7b-94bc-43ca-b3a8-efc77429bd9c",
   "metadata": {},
   "source": [
    "### Vision Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89768a2-4cb6-4b95-8386-6852fc213adf",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/14.png\" alt=\"https://www.researchgate.net/figure/Example-illustrations-of-six-computer-vision-tasks-The-semantic-and-instance_fig2_349483624\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba2a9f4-8358-4873-b446-9da8e5368138",
   "metadata": {},
   "source": [
    "#### Optical Character Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320d2c3-67be-4011-b142-a5e2fe8e9611",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/22.png\" alt=\"https://www.egnyte.com/guides/governance/optical-character-recognition\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39654e8a-483e-4eeb-81c0-3c48bcbe7004",
   "metadata": {},
   "source": [
    "#### Image Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdedaa0-7085-4161-a24f-fade90ce5ef3",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/20.jpg\" alt=\"https://www.mathworks.com/discovery/image-registration.html\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddec222-9ec2-4532-a816-af59286457a8",
   "metadata": {},
   "source": [
    "#### Image Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a6b5e-c7fd-422b-96f2-a65fa93eeb1a",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/23.png\" alt=\"https://towardsdatascience.com/image-captioning-in-deep-learning-9cd23fb4d8d2\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ece97-a540-4a41-9528-8eb7495a0c89",
   "metadata": {},
   "source": [
    "### Voice Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88ad12-4a10-473c-89f0-179f2b2687b2",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/15.jpg\" alt=\"https://twitter.com/huggingface/status/1450797307310616576\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6b3e0-957b-4c86-b724-7375b78b49fc",
   "metadata": {},
   "source": [
    "#### Source Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbfab7-4bd7-478d-94ad-0de5327a9785",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/24.png\" alt=\"https://source-separation.github.io/tutorial/intro/src_sep_101.html\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36399e-bdc1-4436-9bfc-a33c934a5584",
   "metadata": {},
   "source": [
    "#### Speaker Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6fe567-a9cd-4575-9aec-cc475dcf8bd2",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/25.png\" alt=\"https://partner.phonexia.com/kb/sp/speech-platform/spe/technologies-available/speaker-identification/\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df33cdc-dc17-4075-a1d1-814d74805af2",
   "metadata": {},
   "source": [
    "#### Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91348c5c-40b5-4905-bba0-266ca1105a46",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/21.jpg\" alt=\"https://github.com/PrudhviGNV/Speech-Emotion-Recognization\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa17f97-18ae-481a-b75e-b75e45568d00",
   "metadata": {},
   "source": [
    "#### ASR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa62c1e-14a6-4166-831d-ebcbeb07caa9",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/22.jpg\" alt=\"https://github.com/PrudhviGNV/Speech-Emotion-Recognization\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34eb7d-3047-4513-8067-5f602e57dcd8",
   "metadata": {},
   "source": [
    "#### Command Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08836ced-7400-4780-b4a8-f3c62e55401c",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/28.png\" alt=\"https://fosspost.org/open-source-speech-recognition/\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b732102-1fa0-42e3-9947-450fa2aba631",
   "metadata": {},
   "source": [
    "#### Diarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281ad91-14dd-40f1-85fc-21ac0575e49f",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/29.png\" alt=\"https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/speaker_diarization/intro.html\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad3137-9972-42fc-b1d5-0e2d6d9afa1f",
   "metadata": {},
   "source": [
    "#### Text to Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390da89-5c90-4405-9fe0-7c274bd3ae68",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"src/23.jpg\" alt=\"\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essential-ai",
   "language": "python",
   "name": "essential-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
